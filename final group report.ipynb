{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35fecdb0-a6ef-4a99-9baf-68a6cbae20aa",
   "metadata": {},
   "source": [
    "# Final Group Report\n",
    "#### *Group 11: Calvin Choi, Ruby Liu, Muhan Yang, Leon Zhang*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83505720-e447-49a1-b1cc-dc73c4cb68f9",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e1ede4-e447-4666-b25f-4132321ccc12",
   "metadata": {},
   "source": [
    "GitHub is one of the largest collection of open source software in the world (Borges et al., 2016). One feature of hosted repositories in Github is that they allow GitHub users to *star* them, which is mainly used for fellow developers to show appreciation, manifest interest or satisfaction with the current project, or bookmark a certain repository for future utility (Begel et al., 2013). Past research had shown that factors, such as programming languages, number of forks, number of commits, application domains, and so on, may affect the number of stars a GitHub repository obtains, according to Borges et al. (2016).\n",
    "\n",
    "Our project further investigated potential statistical models on various factors that might relate to numbers of stars in popular GitHub repositories, based on a dataset of information of the most popular GitHub repositories. The dataset we are using is the Most Popular Github Repositories (Projects) dataset from Kaggle (URL: https://www.kaggle.com/datasets/donbarbos/github-repos/data), which contains a list of top GitHub project repositories by the number of stars. The data is collected using GitHub search API and the query function to obtain projects with over 167 stars.\n",
    "\n",
    "The repositories dataset consists of 215,029 project repositories (i.e., rows/observations) and 24 columns (i.e., variables) in total. Of the 24 columns, there are five columns containing the integer type of data of repositories: Size, Stars, Forks, Issues, and Watchers, and the data type of the rest 19 variables are characters. Of the 19 columns, there are nine binary variables that contain data coded as \"True\" or \"False\" - Has.Issues, Has.Projects, Has.Downloads, Has.Wiki, Has.Pages, Has.Discussions, Is.Fork, Is.Archived, and Is.Template. There are also two columns, consisting temporal data as character data type, within the rest ten variables: Created.At and Updated.At.\n",
    "\n",
    "For our purposes of the project, we aim to build a predictive model and an inferential model using the number of stars as the outcome variable, and figure out the most significant factors/characteristic of the repository on its number of stars received. Here are our two questions:\n",
    "1. What characteristic(s) of the GitHub repository can help to predict the number of stars/likes the repository received?\n",
    "2. INFERENTIAL QUESTION ----------------\n",
    "\n",
    "The first one is mostly proposed for making predictions on the number of stars the top repositories received based on the data. This question is an exploratory one and is aiming to find a best predictive model for Stars, using the knowledge from model selection and evaluation.\n",
    "\n",
    "SAY SOMETHING ABOUT THE SECOND ONE?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e4f2f7-93bc-499b-869f-c5f6e929e072",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e29ea65-6541-49ae-a7a9-a0c37bb1615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import R libraries\n",
    "library(tidyverse)\n",
    "library(GGally)\n",
    "library(mltools)\n",
    "library(leaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bcccd5-a12b-4461-875d-782729d0ca61",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b1d90-389d-48df-9041-bd7f0109c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# github link to csv dataset\n",
    "link <- \"https://raw.githubusercontent.com/splashhhhhh/stat301/main/repositories.csv\"\n",
    "\n",
    "# read data\n",
    "data <- read.csv(link)\n",
    "\n",
    "# see first few lines of the dataset\n",
    "# head(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6573f21-0319-42b6-9d92-4e17096b436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check NAs, 0s, and empty values\n",
    "colSums(data==0)\n",
    "colSums(data==\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338483c6-238a-4a6e-b684-1f81b12847e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out 0s and empty values\n",
    "data <- data %>%\n",
    "    filter(Size != 0, Forks != 0, Issues != 0) %>%\n",
    "    filter(Name != \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dee754a-2188-47f0-80e3-ea3cc000468e",
   "metadata": {},
   "source": [
    "For default branch column, most of its data is in main and master. Therefore, we will filter out the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf485aa-9130-4802-9f64-e11b0d25640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter default branch to contain only main and master\n",
    "data <- data %>%\n",
    "    filter(Default.Branch == \"main\" | Default.Branch == \"master\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14289a52-b138-409e-a8db-00c4f3a90937",
   "metadata": {},
   "source": [
    "Since the dataset contains huge number of observations, we are only going to use 3,000 observations randomly drawn from the entire data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e565118f-0b56-401d-b52f-81ca171e6788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random selection of 3,000 observations\n",
    "data_s <- sample_n(data, 3000, replace = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d962001-a5b0-4aaa-93c6-e02528718388",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85629338-2f2e-490d-86f0-957a88dc0204",
   "metadata": {},
   "source": [
    "#### Predictive question:\n",
    "We were going to first split the sample data containing 3,000 random selected samples into training set and testing set using a 70-30 ratio basis, use training set to determine a well-trained model using Linear Regression function, and test our model using the testing set, which contains 30% of 3000-observation sample data (i.e., 0.3*3000 = 900 observations) randomly selected from our dataset.\n",
    "\n",
    "Using the forward stepwise selection, we can use the BIC (Bayesian Information Criterion) of each model to select the model, since we want the model to be predictive rather than generative. We can also plot the Cp plot of the model out and select the minimum Cp model. Also, BIC can be used to approximate the test MSE, without looking at the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4614c1-9da5-428e-8e41-07c526f0a41c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce89b3e-bade-4641-be89-2fe5228bdb91",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae979bbf-48f5-4ed7-8515-e427c50fa7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing set\n",
    "data_s$ID <- rownames(data_s)\n",
    "training_data <- sample_n(data_s, size = nrow(data_s) * 0.70,\n",
    "  replace = FALSE\n",
    ")\n",
    "\n",
    "testing_data <- anti_join(data_s,\n",
    "  training_data,\n",
    "  by = \"ID\"\n",
    ")\n",
    "\n",
    "training_data <- training_data %>% select(-\"ID\")\n",
    "testing_data <- testing_data %>% select(-\"ID\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aec20cd-3d7a-4c5f-979e-d8f184dc0c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build an additive predictive model\n",
    "data_full_OLS <- lm(Stars ~ .,\n",
    "  training_data\n",
    ")\n",
    "# data_full_OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf98b59-1f69-48cd-b448-9e7395ace119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the (out-of-sample) predicted values\n",
    "data_test_pred_full_OLS <- predict(data_full_OLS, newdata = testing_data)\n",
    "# head(data_test_pred_full_OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6410ad9-cd79-4db1-9c57-61ac6594f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the Root Mean Squared Error (RMSE) using data from the test set \n",
    "data_RMSE_models <- tibble(\n",
    "  Model = \"OLS Full Regression\",\n",
    "  RMSE = rmse(\n",
    "    data_test_pred_full_OLS,\n",
    "    testing_data$Stars\n",
    "  )\n",
    ")\n",
    "# data_RMSE_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0dc2a2-9736-4ed4-83e7-d13ec857ede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a reduced LR using the forward selection algorithm from training set\n",
    "data_forward_sel <- regsubsets(\n",
    "  x = Stars ~., nvmax = 9,\n",
    "  data = training_data,\n",
    "  method = \"forward\"\n",
    ")\n",
    "# data_forward_sel\n",
    "\n",
    "data_fwd_summary <- summary(data_forward_sel)\n",
    "\n",
    "data_fwd_summary <- tibble(\n",
    "   n_input_variables = 1:9,\n",
    "   RSS = data_fwd_summary$rss,\n",
    "   BIC = data_fwd_summary$bic,\n",
    "   Cp = data_fwd_summary$cp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37666b33-c63d-452c-a5b7-a6daad32f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the size of the model that minimizes Cp\n",
    "cp_min = which.min(data_fwd_summary$Cp)\n",
    "\n",
    "# Find the name of the variables for the best model\n",
    "selected_var <- names(coef(data_forward_sel, cp_min))[-1]\n",
    "\n",
    "# Reduce dataset to only include the selected predictors\n",
    "training_subset <- training_data %>% select(all_of(selected_var),Stars)\n",
    "\n",
    "# Train the predictive model\n",
    "data_red_OLS <- lm(Stars ~ .,\n",
    "  data = training_subset\n",
    ")\n",
    "\n",
    "# summary(data_red_OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4427c1fb-caa1-4b83-bc4a-9720c55f2949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the trained model to predict the responses of the testing set\n",
    "data_test_pred_red_OLS <- predict(data_red_OLS, newdata = testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997e1ef5-a251-430c-b402-809d25f6a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the RMSE of predicted stars in testing set\n",
    "data_RMSE_models <- rbind(\n",
    "  data_RMSE_models,\n",
    "  tibble(\n",
    "    Model = \"OLS Reduced Regression\",\n",
    "    RMSE = rmse(data_test_pred_red_OLS, testing_data$Stars)\n",
    "    )\n",
    "  )\n",
    "data_RMSE_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8743a8bd-76cc-4817-982c-f9128f64f1d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3ba838-bc0c-4b0e-bc18-8f6611d29d5b",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1959f14-87a0-42d7-8e9e-68610cb75aae",
   "metadata": {},
   "source": [
    "The results showed that the full regression model had a better out-of-sample prediction performance compared to our reduced ones, which indicates that the full OLS regression model is better at making predictions when considering all factors.\n",
    "\n",
    "However, note that this is only a one-time estimate of the true test RMSE based on a random split of the data. If we split the data in a different way or by a different ratio, we might be very likely to obtain a different result, given that the RMSE value difference between the full regression and the reduced regression is quite trivial. \n",
    "\n",
    "Also, since we tend to use simpler statistical model since we would like to have a balance between fit and parsimony when selecting models, we finally would pick the reduced regression model, since it has a similar RMSE compared to the full model, but includes less variables/predictors.\n",
    "\n",
    "Future study might want to include different ways and ratios of splitting the data and see if a similar result can be obtained. Moreover, while making predictions using the current dataset, note that the dataset is relatively large and we only included a random selected sample from it (3000 observations out of 215,029) and it contains a lot of missing data, although we did not include them in our analysis. In addition, the dataset only focused on the most popular repositories on GitHub. Therefore, future studies can use other datasets with more diverse data in terms of the popularity of repositories, and see if the result and prediction can be generalized to the overall GitHub repository population at large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94f8c0a-e507-4f25-aa1e-fa1ea4f49f3d",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9b4ffd-460c-46d6-9d7c-a83d2ea386bc",
   "metadata": {},
   "source": [
    "A. Begel, J. Bosch and M. -A. Storey, \"Social Networking Meets Software Development: Perspectives from GitHub, MSDN, Stack Exchange, and TopCoder,\" in IEEE Software, vol. 30, no. 1, pp. 52-66, Jan.-Feb. 2013, doi: 10.1109/MS.2013.13.\n",
    "\n",
    "H. Borges, A. Hora and M. T. Valente, \"Understanding the Factors That Impact the Popularity of GitHub Repositories,\" 2016 IEEE International Conference on Software Maintenance and Evolution (ICSME), Raleigh, NC, USA, 2016, pp. 334-344, doi: 10.1109/ICSME.2016.31. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59393ed0-2358-4b76-95c6-dcbf49a09d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
